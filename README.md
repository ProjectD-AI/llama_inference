# llama_inference
llama inference for tencentpretraint.
to be continue.
